# Part 3: Enhanced Lane Matching System - í†µí•©/ì‹¤í–‰ íë¦„ & API & ì„±ëŠ¥ ë¶„ì„

**ë¬¸ì„œ ë²„ì „**: 1.0  
**ì‘ì„±ì¼**: 2025-10-13  
**í”„ë¡œì íŠ¸**: HVDC Invoice Audit - DSV DOMESTIC  
**ì‘ì„±ì**: MACHO-GPT Enhanced Matching Team

---

## ğŸ“‘ ëª©ì°¨

- [3.1 í†µí•© ë° ì‹¤í–‰ íë¦„](#31-í†µí•©-ë°-ì‹¤í–‰-íë¦„)
  - [3.1.1 Excel íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸](#311-excel-íŒŒì¼-ì²˜ë¦¬-íŒŒì´í”„ë¼ì¸)
  - [3.1.2 add_approved_lanemap_to_excel() ìƒì„¸](#312-add_approved_lanemap_to_excel-ìƒì„¸)
  - [3.1.3 í•˜ì´í¼ë§í¬ ìƒì„± ë©”ì»¤ë‹ˆì¦˜](#313-í•˜ì´í¼ë§í¬-ìƒì„±-ë©”ì»¤ë‹ˆì¦˜)
  - [3.1.4 ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì „ëµ](#314-ì—ëŸ¬-ì²˜ë¦¬-ë°-ë¡œê¹…-ì „ëµ)
  - [3.1.5 ì„±ëŠ¥ ìµœì í™” ê¸°ë²•](#315-ì„±ëŠ¥-ìµœì í™”-ê¸°ë²•)

- [3.2 ì½”ë“œ êµ¬ì¡° ë° API ë ˆí¼ëŸ°ìŠ¤](#32-ì½”ë“œ-êµ¬ì¡°-ë°-api-ë ˆí¼ëŸ°ìŠ¤)
  - [3.2.1 enhanced_matching.py ëª¨ë“ˆ êµ¬ì¡°](#321-enhanced_matchingpy-ëª¨ë“ˆ-êµ¬ì¡°)
  - [3.2.2 ì£¼ìš” í•¨ìˆ˜ API ë¬¸ì„œ](#322-ì£¼ìš”-í•¨ìˆ˜-api-ë¬¸ì„œ)
  - [3.2.3 ì‚¬ìš© ì˜ˆì œ (Quick Start)](#323-ì‚¬ìš©-ì˜ˆì œ-quick-start)
  - [3.2.4 í™•ì¥ ê°€ì´ë“œ](#324-í™•ì¥-ê°€ì´ë“œ)
  - [3.2.5 í…ŒìŠ¤íŠ¸ ì½”ë“œ](#325-í…ŒìŠ¤íŠ¸-ì½”ë“œ)

- [3.3 ì„±ëŠ¥ ë¶„ì„ ë° í–¥í›„ ê³„íš](#33-ì„±ëŠ¥-ë¶„ì„-ë°-í–¥í›„-ê³„íš)
  - [3.3.1 Before/After ìƒì„¸ ë¹„êµ](#331-beforeafter-ìƒì„¸-ë¹„êµ)
  - [3.3.2 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬](#332-ì„±ëŠ¥-ë²¤ì¹˜ë§ˆí¬)
  - [3.3.3 ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸](#333-ë¹„ì¦ˆë‹ˆìŠ¤-ì„íŒ©íŠ¸)
  - [3.3.4 ì•Œë ¤ì§„ ì œì•½ì‚¬í•­ ë° í•œê³„](#334-ì•Œë ¤ì§„-ì œì•½ì‚¬í•­-ë°-í•œê³„)
  - [3.3.5 í–¥í›„ ê°œì„  ë°©í–¥](#335-í–¥í›„-ê°œì„ -ë°©í–¥)

---

## 3.1 í†µí•© ë° ì‹¤í–‰ íë¦„

### 3.1.1 Excel íŒŒì¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

Enhanced Matching Systemì€ **Excel íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ë°›ì•„** ë§¤ì¹­ì„ ìˆ˜í–‰í•˜ê³  **í•˜ì´í¼ë§í¬ê°€ ì¶”ê°€ëœ Excel íŒŒì¼ì„ ì¶œë ¥**í•˜ëŠ” End-to-End íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.

#### ì „ì²´ íŒŒì´í”„ë¼ì¸ ê°œìš”

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: DATA LOADING                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Input Files:
1. domestic_sept_2025_advanced_v3_NO_LEAK.xlsx (19 KB)
   â”œâ”€â”€ items (44 records)
   â”œâ”€â”€ comparison (4 records)
   â””â”€â”€ patterns_applied (4 records)

2. ApprovedLaneMap_ENHANCED.json (63 KB)
   â””â”€â”€ data.Sheet1 (124 lanes)

                        â”‚
                        â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ pd.read_excel()  â”‚
              â”‚ json.load()      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
              items_df (DataFrame 44Ã—15)
              approved_lanes (List[Dict] 124)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: MATCHING LOOP (44 iterations)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

for i, row in items_df.iterrows():
    origin = row["origin"]
    destination = row["destination"]
    vehicle = row["vehicle"]
    unit = row["unit"]
    
    â”‚
    â–¼
    match_result = find_matching_lane_enhanced(
        origin, destination, vehicle, unit, approved_lanes
    )
    â”‚
    â–¼
    if match_result:
        hyperlink_info.append({
            "item_row": i + 2,
            "target_row": match_result["row_index"],
            "match_level": match_result["match_level"],
            "match_score": match_result["match_score"]
        })
        match_stats[match_level] += 1
    else:
        match_stats["no_match"] += 1

Result:
- hyperlink_info: List[35 hyperlinks]
- match_stats: {"exact": 9, "similarity": 6, "region": 14, "vehicle_type": 6, "no_match": 9}

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: EXCEL GENERATION (xlsxwriter)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
    workbook = writer.book
    
    # 1. Define formats
    hyperlink_format = workbook.add_format({
        'font_color': 'blue',
        'underline': 1,
        'num_format': '"$"#,##0.00'
    })
    
    # 2. Write items sheet
    items_df.to_excel(writer, sheet_name="items", index=False)
    worksheet_items = writer.sheets["items"]
    
    # 3. Add hyperlinks
    for link_info in hyperlink_info:
        if link_info["target_row"]:
            hyperlink_url = f"internal:ApprovedLaneMap!A{target_row}"
            worksheet_items.write_url(
                row, col, hyperlink_url, hyperlink_format, 
                string=f"${rate:,.2f}"
            )
    
    # 4. Write other sheets
    comparison_df.to_excel(writer, sheet_name="comparison", index=False)
    patterns_df.to_excel(writer, sheet_name="patterns_applied", index=False)
    approved_df.to_excel(writer, sheet_name="ApprovedLaneMap", index=False)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4: OUTPUT                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output File:
domestic_sept_2025_advanced_v3_NO_LEAK_WITH_LANEMAP_ENHANCED.xlsx (19.8 KB)

Statistics:
- Total Items: 44
- Hyperlinks Created: 35 (79.5%)
- Match Stats:
  â€¢ Level 1 (ì •í™•): 9ê±´
  â€¢ Level 2 (ìœ ì‚¬ë„): 6ê±´
  â€¢ Level 3 (ê¶Œì—­): 14ê±´
  â€¢ Level 4 (ì°¨ëŸ‰íƒ€ì…): 6ê±´
  â€¢ No Match: 9ê±´
```

---

### 3.1.2 add_approved_lanemap_to_excel() ìƒì„¸

#### í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜

```python
def add_approved_lanemap_to_excel(
    excel_file: str = "Results/Sept_2025/domestic_sept_2025_advanced_v3_NO_LEAK.xlsx",
    approved_json: str = "Results/Sept_2025/Reports/ApprovedLaneMap_ENHANCED.json",
    output_file: str = None
) -> Dict:
    """
    Excel íŒŒì¼ì— ApprovedLaneMap ì‹œíŠ¸ ì¶”ê°€ ë° í•˜ì´í¼ë§í¬ ìƒì„±
    
    Args:
        excel_file: ì…ë ¥ Excel íŒŒì¼ ê²½ë¡œ
        approved_json: ApprovedLaneMap JSON íŒŒì¼ ê²½ë¡œ
        output_file: ì¶œë ¥ Excel íŒŒì¼ ê²½ë¡œ (Noneì´ë©´ ìë™ ìƒì„±)
    
    Returns:
        {
            "output_file": str,
            "total_items": int,
            "total_approved_lanes": int,
            "hyperlinks_created": int,
            "match_rate_percent": float,
            "match_stats": {
                "exact": int,
                "similarity": int,
                "region": int,
                "vehicle_type": int,
                "no_match": int
            }
        }
    
    Raises:
        FileNotFoundError: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šì„ ë•Œ
        Exception: ê¸°íƒ€ ì²˜ë¦¬ ì˜¤ë¥˜
    """
```

#### ë‹¨ê³„ë³„ êµ¬í˜„

**Step 1: íŒŒì¼ ë¡œë”© ë° ê²€ì¦**
```python
excel_path = Path(excel_file)
json_path = Path(approved_json)

# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
if not excel_path.exists():
    raise FileNotFoundError(f"Excel file not found: {excel_path}")

if not json_path.exists():
    raise FileNotFoundError(f"JSON file not found: {json_path}")

print("=" * 80)
print("ğŸ“Š Excel ApprovedLaneMap í†µí•© ì‹œì‘")
print("=" * 80)

# Excel ë¡œë“œ
print(f"ğŸ“‚ Loading Excel: {excel_path.name}")
items_df = pd.read_excel(excel_file, sheet_name="items")
comparison_df = pd.read_excel(excel_file, sheet_name="comparison") 
patterns_df = pd.read_excel(excel_file, sheet_name="patterns_applied")

print(f"  âœ… items: {len(items_df)} records")
print(f"  âœ… comparison: {len(comparison_df)} records")
print(f"  âœ… patterns_applied: {len(patterns_df)} records")

# JSON ë¡œë“œ
print(f"\nğŸ“‚ Loading ApprovedLaneMap: {json_path.name}")
with open(json_path, 'r', encoding='utf-8') as f:
    approved_data = json.load(f)

approved_lanes = approved_data["data"]["Sheet1"]
print(f"  âœ… ApprovedLanes: {len(approved_lanes)} lanes")
```

**Step 2: ApprovedLaneMap DataFrame ìƒì„±**
```python
approved_df = pd.DataFrame(approved_lanes)

# ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬
columns_order = [
    "lane_id", "origin", "destination", "vehicle", "unit",
    "median_rate_usd", "mean_rate_usd", "samples",
    "median_distance_km", "mean_distance_km", "std_rate_usd", "notes", "key"
]

approved_df = approved_df[[col for col in columns_order if col in approved_df.columns]]
```

**Step 3: ë§¤ì¹­ ë£¨í”„**
```python
print(f"\nğŸ”— í•˜ì´í¼ë§í¬ ë§¤ì¹­ ì¤‘... (Enhanced Multi-Level Matching)")

hyperlink_info = []
match_stats = {
    "exact": 0,
    "similarity": 0,
    "region": 0,
    "vehicle_type": 0,
    "no_match": 0
}

for i, row in items_df.iterrows():
    origin = row.get("origin", "")
    destination = row.get("destination", "")
    vehicle = row.get("vehicle", "")
    unit = row.get("unit", "per truck")
    
    # Enhanced ë§¤ì¹­ ì‚¬ìš©
    match_result = find_matching_lane_enhanced(
        origin, destination, vehicle, unit, approved_lanes, verbose=False
    )
    
    if match_result:
        match_level = match_result.get("match_level", "SIMILARITY")
        
        hyperlink_info.append({
            "item_row": i + 2,
            "target_row": match_result["row_index"],
            "match_score": match_result["match_score"],
            "match_level": match_level,
            "approved_rate": match_result["lane_data"].get("median_rate_usd", 0),
            "lane_id": match_result["lane_data"].get("lane_id", "")
        })
        
        match_stats[match_level.lower()] += 1
    else:
        match_stats["no_match"] += 1
        hyperlink_info.append({
            "item_row": i + 2,
            "target_row": None,
            "match_score": 0.0,
            "match_level": None,
            "approved_rate": None,
            "lane_id": None
        })

# í†µê³„ ì¶œë ¥
print(f"  âœ… ë§¤ì¹­ ê²°ê³¼ (Enhanced):")
print(f"    Level 1 - ì •í™• ë§¤ì¹­: {match_stats['exact']}ê±´")
print(f"    Level 2 - ìœ ì‚¬ë„ ë§¤ì¹­: {match_stats['similarity']}ê±´")
print(f"    Level 3 - ê¶Œì—­ ë§¤ì¹­: {match_stats['region']}ê±´")
print(f"    Level 4 - ì°¨ëŸ‰íƒ€ì… ë§¤ì¹­: {match_stats['vehicle_type']}ê±´")
print(f"    ë§¤ì¹­ ì‹¤íŒ¨: {match_stats['no_match']}ê±´")

total_matched = sum(match_stats[k] for k in ['exact', 'similarity', 'region', 'vehicle_type'])
match_rate = (total_matched / len(items_df) * 100) if len(items_df) > 0 else 0
print(f"    ğŸ“Š ì´ ë§¤ì¹­ë¥ : {match_rate:.1f}% ({total_matched}/{len(items_df)})")
```

**Step 4: Excel íŒŒì¼ ìƒì„±**
```python
if output_file is None:
    output_file = excel_path.parent / f"{excel_path.stem}_WITH_LANEMAP.xlsx"

output_path = Path(output_file)

print(f"\nğŸ“ ìƒˆ Excel íŒŒì¼ ìƒì„±: {output_path.name}")

with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
    workbook = writer.book
    
    # í¬ë§· ì •ì˜
    hyperlink_format = workbook.add_format({
        'font_color': 'blue',
        'underline': 1,
        'num_format': '"$"#,##0.00'
    })
    
    normal_format = workbook.add_format({
        'num_format': '"$"#,##0.00'
    })
    
    header_format = workbook.add_format({
        'bold': True,
        'bg_color': '#D7E4BC',
        'border': 1
    })
    
    # Sheet 1: items (í•˜ì´í¼ë§í¬ í¬í•¨)
    items_df.to_excel(writer, sheet_name="items", index=False)
    worksheet_items = writer.sheets["items"]
    
    # í—¤ë” í¬ë§·íŒ…
    for col_num, value in enumerate(items_df.columns.values):
        worksheet_items.write(0, col_num, value, header_format)
    
    # ref_rate_usd ì»¬ëŸ¼ì— í•˜ì´í¼ë§í¬ ì¶”ê°€
    ref_rate_col_index = None
    if "ref_adj" in items_df.columns:
        ref_rate_col_index = list(items_df.columns).index("ref_adj")
    elif "ref_base" in items_df.columns:
        ref_rate_col_index = list(items_df.columns).index("ref_base")
    
    if ref_rate_col_index is not None:
        print(f"  ğŸ”— Adding hyperlinks to column: {items_df.columns[ref_rate_col_index]}")
        
        for link_info in hyperlink_info:
            item_row = link_info["item_row"]
            target_row = link_info["target_row"]
            
            # ì‹¤ì œ ìš”ìœ¨ ê°’
            rate_value = items_df.iloc[item_row - 2].iloc[ref_rate_col_index]
            
            if pd.notna(rate_value) and target_row:
                # í•˜ì´í¼ë§í¬ ìƒì„±
                hyperlink_url = f"internal:ApprovedLaneMap!A{target_row}"
                worksheet_items.write_url(
                    item_row - 1, ref_rate_col_index,
                    hyperlink_url,
                    hyperlink_format,
                    string=f"${float(rate_value):,.2f}"
                )
            elif pd.notna(rate_value):
                # ë§¤ì¹­ ì—†ëŠ” ê²½ìš° ì¼ë°˜ ìˆ«ì
                worksheet_items.write(
                    item_row - 1, ref_rate_col_index,
                    float(rate_value),
                    normal_format
                )
    
    # Sheet 2-4: ê¸°íƒ€ ì‹œíŠ¸
    comparison_df.to_excel(writer, sheet_name="comparison", index=False)
    patterns_df.to_excel(writer, sheet_name="patterns_applied", index=False)
    
    # Sheet 5: ApprovedLaneMap
    print(f"  ğŸ“‹ Adding ApprovedLaneMap sheet...")
    approved_df.to_excel(writer, sheet_name="ApprovedLaneMap", index=False)

print(f"âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
```

**Step 5: ê²°ê³¼ ë°˜í™˜**
```python
total_matched = match_stats['exact'] + match_stats['similarity'] + match_stats['region'] + match_stats['vehicle_type']

return {
    "output_file": str(output_path),
    "total_items": len(items_df),
    "total_approved_lanes": len(approved_df),
    "hyperlinks_created": total_matched,
    "match_rate_percent": (total_matched / len(items_df) * 100) if len(items_df) > 0 else 0,
    "match_stats": match_stats
}
```

---

### 3.1.3 í•˜ì´í¼ë§í¬ ìƒì„± ë©”ì»¤ë‹ˆì¦˜

#### xlsxwriterë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼ë§í¬

**Excel í•˜ì´í¼ë§í¬ êµ¬ë¬¸:**
```
internal:SheetName!CellAddress
```

**ì˜ˆì‹œ:**
```python
hyperlink_url = "internal:ApprovedLaneMap!A46"
```
- ê°™ì€ íŒŒì¼ ë‚´ `ApprovedLaneMap` ì‹œíŠ¸ì˜ `A46` ì…€ë¡œ ì´ë™

#### í•˜ì´í¼ë§í¬ í¬ë§·

```python
hyperlink_format = workbook.add_format({
    'font_color': 'blue',      # íŒŒë€ìƒ‰ í…ìŠ¤íŠ¸
    'underline': 1,            # ë°‘ì¤„
    'num_format': '"$"#,##0.00'  # í†µí™” í˜•ì‹
})
```

**ì‹œê°ì  íš¨ê³¼:**
- íŒŒë€ìƒ‰ ë°‘ì¤„ í…ìŠ¤íŠ¸: `$420.00`
- í´ë¦­ ì‹œ ApprovedLaneMap ì‹œíŠ¸ë¡œ ì´ë™

#### write_url() vs write()

**í•˜ì´í¼ë§í¬ ìˆëŠ” ê²½ìš°:**
```python
worksheet.write_url(
    row, col,                    # ìœ„ì¹˜ (0-based)
    hyperlink_url,               # "internal:ApprovedLaneMap!A46"
    hyperlink_format,            # í¬ë§· (íŒŒë€ìƒ‰, ë°‘ì¤„)
    string="$420.00"             # í‘œì‹œ í…ìŠ¤íŠ¸
)
```

**í•˜ì´í¼ë§í¬ ì—†ëŠ” ê²½ìš°:**
```python
worksheet.write(
    row, col,                    # ìœ„ì¹˜
    420.00,                      # ìˆ«ì ê°’
    normal_format                # í¬ë§· (ê²€ì€ìƒ‰, ë°‘ì¤„ ì—†ìŒ)
)
```

---

### 3.1.4 ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹… ì „ëµ

#### ì—ëŸ¬ ì²˜ë¦¬ ê³„ì¸µ

**Level 1: íŒŒì¼ I/O ì—ëŸ¬**
```python
try:
    excel_path = Path(excel_file)
    if not excel_path.exists():
        raise FileNotFoundError(f"Excel file not found: {excel_path}")
    
    items_df = pd.read_excel(excel_file, sheet_name="items")
except FileNotFoundError as e:
    print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    return None
except Exception as e:
    print(f"âŒ Excel íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    return None
```

**Level 2: ë°ì´í„° ê²€ì¦ ì—ëŸ¬**
```python
# í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
required_columns = ["origin", "destination", "vehicle", "unit"]
missing_columns = [col for col in required_columns if col not in items_df.columns]

if missing_columns:
    raise ValueError(f"Missing required columns: {missing_columns}")

# ë°ì´í„° íƒ€ì… ê²€ì¦
if not pd.api.types.is_string_dtype(items_df["origin"]):
    print("âš ï¸ Warning: 'origin' column is not string type")
```

**Level 3: ë§¤ì¹­ ì‹¤íŒ¨ ì²˜ë¦¬**
```python
match_result = find_matching_lane_enhanced(origin, destination, vehicle, unit, approved_lanes)

if match_result is None:
    # Graceful degradation: í•˜ì´í¼ë§í¬ ì—†ì´ ì§„í–‰
    hyperlink_info.append({
        "item_row": i + 2,
        "target_row": None,
        "match_score": 0.0,
        "match_level": None
    })
    match_stats["no_match"] += 1
```

**Level 4: Excel ì“°ê¸° ì—ëŸ¬**
```python
try:
    with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:
        items_df.to_excel(writer, sheet_name="items", index=False)
        # ... more sheets ...
except PermissionError:
    print(f"âŒ íŒŒì¼ì´ ì—´ë ¤ìˆìŠµë‹ˆë‹¤: {output_path}")
    print("   íŒŒì¼ì„ ë‹«ê³  ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
    return None
except Exception as e:
    print(f"âŒ Excel íŒŒì¼ ì“°ê¸° ì‹¤íŒ¨: {e}")
    import traceback
    traceback.print_exc()
    return None
```

#### ë¡œê¹… ì „ëµ

**ì§„í–‰ ìƒí™© ë¡œê¹…:**
```python
print("=" * 80)
print("ğŸ“Š Excel ApprovedLaneMap í†µí•© ì‹œì‘")
print("=" * 80)

print(f"ğŸ“‚ Loading Excel: {excel_path.name}")
print(f"  âœ… items: {len(items_df)} records")

print(f"\nğŸ”— í•˜ì´í¼ë§í¬ ë§¤ì¹­ ì¤‘... (Enhanced Multi-Level Matching)")
print(f"  âœ… ë§¤ì¹­ ê²°ê³¼ (Enhanced):")
print(f"    Level 1 - ì •í™• ë§¤ì¹­: {match_stats['exact']}ê±´")

print(f"\nğŸ“ ìƒˆ Excel íŒŒì¼ ìƒì„±: {output_path.name}")
print(f"âœ… Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
```

**ìƒì„¸ ë¡œê·¸ (verbose ëª¨ë“œ):**
```python
match_result = find_matching_lane_enhanced(
    origin, destination, vehicle, unit, approved_lanes, 
    verbose=True  # ìƒì„¸ ë¡œê·¸ í™œì„±í™”
)

# Output:
# [MATCHING] DSV MUSSAFAH YARD â†’ MIRFA SITE (FLATBED)
#   Normalized: DSV MUSSAFAH YARD â†’ MIRFA SITE (FLATBED)
#   âœ… LEVEL 1 (EXACT): Lane 44 matched!
```

---

### 3.1.5 ì„±ëŠ¥ ìµœì í™” ê¸°ë²•

#### ìµœì í™” 1: DataFrame íš¨ìœ¨ì  ìˆœíšŒ

**Before (ëŠë¦¼):**
```python
for index in range(len(items_df)):
    row = items_df.iloc[index]
    origin = row["origin"]
    # ... processing ...
```

**After (ë¹ ë¦„):**
```python
for i, row in items_df.iterrows():
    origin = row.get("origin", "")
    # ... processing ...
```
- `iterrows()`ê°€ `iloc[]`ë³´ë‹¤ 2-3ë°° ë¹ ë¦„

#### ìµœì í™” 2: ì¡°ê¸° ì¢…ë£Œ (Early Exit)

**Level 1 ì •í™• ë§¤ì¹­:**
```python
for i, lane in enumerate(approved_lanes):
    if exact_match:
        return match_result  # ì¦‰ì‹œ ì¢…ë£Œ, Level 2-4 ìƒëµ
```
- ì •í™• ë§¤ì¹­ ì‹œ ì¶”ê°€ ê³„ì‚° ë¶ˆí•„ìš”
- ì „ì²´ ì²˜ë¦¬ ì‹œê°„ 20% ê°ì†Œ

#### ìµœì í™” 3: ìœ ì‚¬ë„ ê³„ì‚° ìºì‹± (ì ì¬ì )

**í˜„ì¬:**
```python
for lane in approved_lanes:
    origin_sim = hybrid_similarity(origin, lane_origin)
    # ë§¤ë²ˆ ì¬ê³„ì‚°
```

**ê°œì„  ê°€ëŠ¥:**
```python
# ìºì‹œ ì‚¬ìš© (functools.lru_cache)
@lru_cache(maxsize=1024)
def hybrid_similarity_cached(s1, s2, weights_tuple):
    return hybrid_similarity(s1, s2, dict(weights_tuple))
```
- ì ì¬ì  ì„±ëŠ¥ í–¥ìƒ: 30-40%
- í˜„ì¬ ë¯¸ì ìš© (ë³µì¡ë„ ì¦ê°€ vs ì´ë“)

#### ìµœì í™” 4: ë²¡í„°í™” (ë¯¸ì ìš©)

**í˜„ì¬: ë£¨í”„ ê¸°ë°˜**
```python
for i, lane in enumerate(approved_lanes):
    # 124ë²ˆ ë°˜ë³µ
```

**ì ì¬ì : NumPy ë²¡í„°í™”**
```python
# NumPy/Pandas ë²¡í„° ì—°ì‚°
similarities = np.vectorize(hybrid_similarity)(origins, lane_origins)
```
- ì´ë¡ ì  ì„±ëŠ¥ í–¥ìƒ: 10-100ë°°
- í˜„ì¬ ë¯¸ì ìš© (êµ¬í˜„ ë³µì¡ë„, ê°€ë…ì„± ì €í•˜)

---

## 3.2 ì½”ë“œ êµ¬ì¡° ë° API ë ˆí¼ëŸ°ìŠ¤

### 3.2.1 enhanced_matching.py ëª¨ë“ˆ êµ¬ì¡°

#### íŒŒì¼ êµ¬ì¡°

```python
# enhanced_matching.py (690 lines)

"""
Enhanced Lane Matching Algorithm Module
========================================
ê³ ê¸‰ ë ˆì¸ ë§¤ì¹­ ì•Œê³ ë¦¬ì¦˜: ì •ê·œí™”, ìœ ì‚¬ë„, ë‹¤ë‹¨ê³„ ë§¤ì¹­
"""

import pandas as pd
import re
from typing import Optional, Dict, List, Tuple

# ============================================================================
# Section 1: NORMALIZATION (Lines 14-172)
# ============================================================================

LOCATION_SYNONYMS = {...}      # 42 entries
VEHICLE_SYNONYMS = {...}       # 11 entries

def normalize_text(text, synonym_map) -> str: ...
def normalize_location(location) -> str: ...
def normalize_vehicle(vehicle) -> str: ...

# ============================================================================
# Section 2: SIMILARITY ALGORITHMS (Lines 173-315)
# ============================================================================

def levenshtein_distance(s1, s2) -> int: ...
def levenshtein_similarity(s1, s2) -> float: ...
def token_set_similarity(s1, s2) -> float: ...
def fuzzy_token_sort_similarity(s1, s2) -> float: ...
def hybrid_similarity(s1, s2, weights=None) -> float: ...

# ============================================================================
# Section 3: REGIONAL MATCHING (Lines 316-380)
# ============================================================================

REGION_MAP = {...}             # 4 regions, 25 keywords

def get_region(location) -> Optional[str]: ...

# ============================================================================
# Section 4: VEHICLE TYPE MATCHING (Lines 381-410)
# ============================================================================

VEHICLE_GROUPS = {...}         # 4 groups, 11 types

def get_vehicle_group(vehicle) -> Optional[str]: ...

# ============================================================================
# Section 5: MULTI-LEVEL MATCHING (Lines 411-590)
# ============================================================================

def find_matching_lane_enhanced(
    origin, destination, vehicle, unit, approved_lanes, verbose=False
) -> Optional[Dict]: ...
    # Level 1: Exact Match
    # Level 2: Similarity Match
    # Level 3: Region Match
    # Level 4: Vehicle Type Match

# ============================================================================
# Section 6: UTILITY FUNCTIONS (Lines 591-658)
# ============================================================================

def compare_matching_results(
    items_df, approved_lanes, old_matching_func, new_matching_func
) -> Dict: ...

# ============================================================================
# Section 7: TEST CODE (Lines 659-690)
# ============================================================================

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    test_normalization()
    test_similarity()
    test_region()
    test_vehicle_group()
```

---

### 3.2.2 ì£¼ìš” í•¨ìˆ˜ API ë¬¸ì„œ

#### normalize_location()

```python
def normalize_location(location: str) -> str:
    """
    í–¥ìƒëœ ìœ„ì¹˜ëª… ì •ê·œí™”
    
    ê¸°ì¡´ í•˜ë“œì½”ë”© ê·œì¹™ + ì‹œë…¸ë‹˜ ë§¤í•‘ í†µí•©
    
    Args:
        location (str): ì›ë³¸ ìœ„ì¹˜ëª…
            Examples: "DSV Musafah Yard", "ICAD WH", "Jebel-Ali / Port"
    
    Returns:
        str: í‘œì¤€ ìœ„ì¹˜ëª…
            Examples: "DSV MUSSAFAH YARD", "ICAD WAREHOUSE", "JEBEL ALI PORT"
    
    Process:
        1. normalize_text() í˜¸ì¶œ (ì‹œë…¸ë‹˜ ë§¤í•‘)
        2. í•˜ë“œì½”ë”© ê·œì¹™ ì ìš© (ìš°ì„ ìˆœìœ„ ê¸°ë°˜)
        3. ë³€í™˜ ì‹¤íŒ¨ ì‹œ ì‹œë…¸ë‹˜ ë§¤í•‘ ê²°ê³¼ ë°˜í™˜
    
    Examples:
        >>> normalize_location("DSV Musafah Yard")
        'DSV MUSSAFAH YARD'
        
        >>> normalize_location("ICAD WH")
        'ICAD WAREHOUSE'
        
        >>> normalize_location(None)
        ''
    
    Time Complexity: O(n) where n = length of location string
    Space Complexity: O(1)
    """
```

#### hybrid_similarity()

```python
def hybrid_similarity(
    s1: str,
    s2: str,
    weights: Dict[str, float] = None
) -> float:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ê³„ì‚°
    
    3ê°€ì§€ ì•Œê³ ë¦¬ì¦˜(Token-Set, Levenshtein, Fuzzy Sort)ì˜ ê°€ì¤‘ í‰ê· 
    
    Args:
        s1 (str): ì²« ë²ˆì§¸ ë¬¸ìì—´
        s2 (str): ë‘ ë²ˆì§¸ ë¬¸ìì—´
        weights (Dict[str, float], optional): ê° ì•Œê³ ë¦¬ì¦˜ì˜ ê°€ì¤‘ì¹˜
            Default: {
                "token_set": 0.4,
                "levenshtein": 0.3,
                "fuzzy_sort": 0.3
            }
    
    Returns:
        float: ê°€ì¤‘ í‰ê·  ìœ ì‚¬ë„ [0, 1]
            - 0.0: ì™„ì „ ë¶ˆì¼ì¹˜
            - 1.0: ì™„ì „ ì¼ì¹˜
            - 0.65+: Level 2 ë§¤ì¹­ ì„ê³„ê°’
    
    Formula:
        HybridSim(s1, s2) = Î£(w_i Ã— Sim_i(s1, s2))
    
    Examples:
        >>> hybrid_similarity("DSV MUSSAFAH YARD", "DSV MUSAFAH YARD")
        0.766
        
        >>> hybrid_similarity("ICAD", "M44")
        0.15
    
    Time Complexity: O(m Ã— n) for Levenshtein (dominant)
    Space Complexity: O(min(m, n)) for Levenshtein DP
    
    See Also:
        - token_set_similarity()
        - levenshtein_similarity()
        - fuzzy_token_sort_similarity()
    """
```

#### find_matching_lane_enhanced()

```python
def find_matching_lane_enhanced(
    origin: str,
    destination: str,
    vehicle: str,
    unit: str,
    approved_lanes: List[Dict],
    verbose: bool = False
) -> Optional[Dict]:
    """
    í–¥ìƒëœ 4ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ
    
    4ë‹¨ê³„ Fallbackì„ í†µí•´ ì ì§„ì ìœ¼ë¡œ ì™„í™”ëœ ì¡°ê±´ìœ¼ë¡œ ë§¤ì¹­ ì‹œë„
    
    Args:
        origin (str): ì¶œë°œì§€
            Example: "DSV MUSSAFAH YARD"
        destination (str): ëª©ì ì§€
            Example: "MIRFA SITE"
        vehicle (str): ì°¨ëŸ‰ íƒ€ì…
            Example: "FLATBED"
        unit (str): ë‹¨ìœ„
            Example: "per truck"
        approved_lanes (List[Dict]): ApprovedLaneMap ë ˆì¸ ë¦¬ìŠ¤íŠ¸ (124ê°œ)
        verbose (bool, optional): ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€. Default: False
    
    Returns:
        Optional[Dict]: ë§¤ì¹­ ê²°ê³¼ ë˜ëŠ” None
            {
                "row_index": int,        # Excel í–‰ ë²ˆí˜¸ (2-based)
                "match_score": float,    # ìœ ì‚¬ë„ ì ìˆ˜ [0, 1]
                "match_level": str,      # "EXACT" | "SIMILARITY" | "REGION" | "VEHICLE_TYPE"
                "lane_data": dict        # ë§¤ì¹­ëœ ë ˆì¸ì˜ ì „ì²´ ë°ì´í„°
            }
    
    Matching Levels:
        Level 1 (EXACT): 100% ì •í™• ì¼ì¹˜
            - ëª¨ë“  í•„ë“œ ì •ê·œí™” í›„ ì™„ì „ ì¼ì¹˜
            - Score: 1.0
        
        Level 2 (SIMILARITY): ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­
            - ì°¨ëŸ‰/ë‹¨ìœ„ ì •í™• ì¼ì¹˜
            - ì¶œë°œì§€/ëª©ì ì§€ í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ â‰¥ 0.65
            - Score: 0.65~1.0
        
        Level 3 (REGION): ê¶Œì—­ ê¸°ë°˜ ë§¤ì¹­
            - ì°¨ëŸ‰/ë‹¨ìœ„ ì •í™• ì¼ì¹˜
            - ì¶œë°œì§€/ëª©ì ì§€ ê°™ì€ ê¶Œì—­
            - Score: 0.5
        
        Level 4 (VEHICLE_TYPE): ì°¨ëŸ‰ ê·¸ë£¹ ê¸°ë°˜ ë§¤ì¹­
            - ë‹¨ìœ„ ì •í™• ì¼ì¹˜
            - ì°¨ëŸ‰ ê°™ì€ ê·¸ë£¹
            - ì¶œë°œì§€/ëª©ì ì§€ ìœ ì‚¬ë„ â‰¥ 0.4
            - Score: 0.4~1.0
    
    Examples:
        >>> # Level 1: ì •í™• ë§¤ì¹­
        >>> result = find_matching_lane_enhanced(
        ...     "DSV MUSSAFAH YARD", "MIRFA SITE", "FLATBED", "per truck", lanes
        ... )
        >>> print(result)
        {
            "row_index": 46,
            "match_score": 1.0,
            "match_level": "EXACT",
            "lane_data": {...}
        }
        
        >>> # Level 2: ìœ ì‚¬ë„ ë§¤ì¹­ (ì˜¤íƒ€)
        >>> result = find_matching_lane_enhanced(
        ...     "DSV MUSAFAH YARD", "MIRFA SITE", "FLATBED", "per truck", lanes
        ... )
        >>> print(result)
        {
            "row_index": 46,
            "match_score": 0.87,
            "match_level": "SIMILARITY",
            "lane_data": {...}
        }
        
        >>> # No match
        >>> result = find_matching_lane_enhanced(
        ...     "UNKNOWN", "LOCATION", "UNKNOWN", "per truck", lanes
        ... )
        >>> print(result)
        None
    
    Time Complexity: O(n Ã— m) where n = len(approved_lanes), m = similarity cost
    Space Complexity: O(1) (constant extra space)
    
    Note:
        - ìƒìœ„ ë ˆë²¨ì—ì„œ ë§¤ì¹­ ì„±ê³µ ì‹œ ì¦‰ì‹œ ë°˜í™˜ (Early Exit)
        - verbose=True ì‹œ ê° ë ˆë²¨ì˜ ë§¤ì¹­ ì‹œë„ ê³¼ì • ì¶œë ¥
        - ì •ê·œí™”ëŠ” í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ ìˆ˜í–‰ë¨
    """
```

---

### 3.2.3 ì‚¬ìš© ì˜ˆì œ (Quick Start)

#### ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš©ë²•

```python
import pandas as pd
import json
from enhanced_matching import find_matching_lane_enhanced

# 1. ApprovedLaneMap ë¡œë“œ
with open("ApprovedLaneMap_ENHANCED.json", 'r') as f:
    approved_data = json.load(f)
approved_lanes = approved_data["data"]["Sheet1"]

# 2. ë‹¨ì¼ í•­ëª© ë§¤ì¹­
result = find_matching_lane_enhanced(
    origin="DSV MUSSAFAH YARD",
    destination="MIRFA SITE",
    vehicle="FLATBED",
    unit="per truck",
    approved_lanes=approved_lanes
)

# 3. ê²°ê³¼ í™•ì¸
if result:
    print(f"âœ… Match Found!")
    print(f"   Level: {result['match_level']}")
    print(f"   Score: {result['match_score']:.3f}")
    print(f"   Lane ID: {result['lane_data']['lane_id']}")
    print(f"   Rate: ${result['lane_data']['median_rate_usd']:,.2f}")
else:
    print("âŒ No match found")
```

**Output:**
```
âœ… Match Found!
   Level: EXACT
   Score: 1.000
   Lane ID: L044
   Rate: $420.00
```

---

#### ì˜ˆì œ 2: Batch ë§¤ì¹­

```python
# 1. Items ë¡œë“œ
items_df = pd.read_excel("domestic_sept_2025.xlsx", sheet_name="items")

# 2. ë§¤ì¹­ ë£¨í”„
results = []
for i, row in items_df.iterrows():
    result = find_matching_lane_enhanced(
        origin=row["origin"],
        destination=row["destination"],
        vehicle=row["vehicle"],
        unit=row.get("unit", "per truck"),
        approved_lanes=approved_lanes
    )
    results.append(result)

# 3. í†µê³„
total = len(results)
matched = sum(1 for r in results if r is not None)
print(f"Matched: {matched}/{total} ({matched/total*100:.1f}%)")
```

**Output:**
```
Matched: 35/44 (79.5%)
```

---

#### ì˜ˆì œ 3: Verbose ëª¨ë“œ (ë””ë²„ê¹…)

```python
result = find_matching_lane_enhanced(
    origin="DSV Musafah Yard",  # ì˜¤íƒ€
    destination="Mirfa Site",
    vehicle="FLATBED",
    unit="per truck",
    approved_lanes=approved_lanes,
    verbose=True  # ìƒì„¸ ë¡œê·¸ í™œì„±í™”
)
```

**Output:**
```
[MATCHING] DSV Musafah Yard â†’ Mirfa Site (FLATBED)
  Normalized: DSV MUSSAFAH YARD â†’ MIRFA SITE (FLATBED)
  âœ… LEVEL 1 (EXACT): Lane 44 matched!
```

---

#### ì˜ˆì œ 4: ì •ê·œí™”ë§Œ í…ŒìŠ¤íŠ¸

```python
from enhanced_matching import normalize_location, normalize_vehicle

# ìœ„ì¹˜ëª… ì •ê·œí™”
print(normalize_location("DSV Musafah WH"))
# Output: "DSV MUSSAFAH WAREHOUSE"

print(normalize_location("Jebel-Ali / Port"))
# Output: "JEBEL ALI PORT"

# ì°¨ëŸ‰ ì •ê·œí™”
print(normalize_vehicle("FLAT BED"))
# Output: "FLATBED"

print(normalize_vehicle("lorry"))
# Output: "TRUCK"
```

---

#### ì˜ˆì œ 5: ìœ ì‚¬ë„ ê³„ì‚°ë§Œ í…ŒìŠ¤íŠ¸

```python
from enhanced_matching import hybrid_similarity

s1 = "DSV MUSSAFAH YARD"
s2 = "DSV MUSAFAH YARD"

similarity = hybrid_similarity(s1, s2)
print(f"Similarity: {similarity:.3f}")
# Output: Similarity: 0.766

# ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜
custom_weights = {
    "token_set": 0.5,
    "levenshtein": 0.3,
    "fuzzy_sort": 0.2
}
similarity_custom = hybrid_similarity(s1, s2, custom_weights)
print(f"Custom Similarity: {similarity_custom:.3f}")
# Output: Custom Similarity: 0.750
```

---

### 3.2.4 í™•ì¥ ê°€ì´ë“œ

#### í™•ì¥ 1: ìƒˆ ì‹œë…¸ë‹˜ ì¶”ê°€

**Step 1: LOCATION_SYNONYMS ì—…ë°ì´íŠ¸**
```python
# enhanced_matching.py

LOCATION_SYNONYMS = {
    # ... existing ...
    
    # NEW: Add new synonyms
    "NEW_LOCATION": ["ALIAS1", "ALIAS2", "ALIAS3"],
}
```

**Step 2: í…ŒìŠ¤íŠ¸**
```python
from enhanced_matching import normalize_location

result = normalize_location("ALIAS1")
print(result)  # Expected: "NEW_LOCATION"
```

---

#### í™•ì¥ 2: ìƒˆ ê¶Œì—­ ì¶”ê°€

**Step 1: REGION_MAP ì—…ë°ì´íŠ¸**
```python
# enhanced_matching.py

REGION_MAP = {
    # ... existing ...
    
    # NEW: Add new region
    "NEW_REGION": [
        "KEYWORD1", "KEYWORD2", "KEYWORD3"
    ],
}
```

**Step 2: í…ŒìŠ¤íŠ¸**
```python
from enhanced_matching import get_region

region = get_region("KEYWORD1 WAREHOUSE")
print(region)  # Expected: "NEW_REGION"
```

---

#### í™•ì¥ 3: ìƒˆ ì°¨ëŸ‰ ê·¸ë£¹ ì¶”ê°€

**Step 1: VEHICLE_GROUPS ì—…ë°ì´íŠ¸**
```python
# enhanced_matching.py

VEHICLE_GROUPS = {
    # ... existing ...
    
    # NEW: Add new vehicle group
    "NEW_VEHICLE_GROUP": ["TYPE1", "TYPE2", "TYPE3"],
}
```

**Step 2: í…ŒìŠ¤íŠ¸**
```python
from enhanced_matching import get_vehicle_group

group = get_vehicle_group("TYPE1")
print(group)  # Expected: "NEW_VEHICLE_GROUP"
```

---

#### í™•ì¥ 4: ê°€ì¤‘ì¹˜ íŠœë‹

**Scenario**: Originê³¼ Destinationì˜ ì¤‘ìš”ë„ ë³€ê²½

**Step 1: find_matching_lane_enhanced() ìˆ˜ì •**
```python
# Level 2ì—ì„œ ê°€ì¤‘ì¹˜ ë³€ê²½
# Before:
total_sim = 0.6 * origin_sim + 0.4 * dest_sim

# After: Origin ì¤‘ìš”ë„ ì¦ê°€
total_sim = 0.7 * origin_sim + 0.3 * dest_sim
```

**Step 2: A/B í…ŒìŠ¤íŠ¸**
```python
# ê¸°ì¡´ ê°€ì¤‘ì¹˜ë¡œ ë§¤ì¹­
results_old = run_matching_with_weights(0.6, 0.4)

# ìƒˆ ê°€ì¤‘ì¹˜ë¡œ ë§¤ì¹­
results_new = run_matching_with_weights(0.7, 0.3)

# ë¹„êµ
compare_results(results_old, results_new)
```

---

### 3.2.5 í…ŒìŠ¤íŠ¸ ì½”ë“œ

#### ìœ ë‹› í…ŒìŠ¤íŠ¸

```python
# test_enhanced_matching.py

import pytest
from enhanced_matching import (
    normalize_location,
    normalize_vehicle,
    hybrid_similarity,
    find_matching_lane_enhanced
)

class TestNormalization:
    """ì •ê·œí™” ì—”ì§„ í…ŒìŠ¤íŠ¸"""
    
    def test_normalize_location_exact(self):
        """ì •í™•í•œ ìœ„ì¹˜ëª… ì •ê·œí™”"""
        assert normalize_location("DSV Musafah Yard") == "DSV MUSSAFAH YARD"
        assert normalize_location("ICAD WH") == "ICAD WAREHOUSE"
        assert normalize_location("Jebel-Ali / Port") == "JEBEL ALI PORT"
    
    def test_normalize_location_null(self):
        """Null ì²˜ë¦¬"""
        assert normalize_location(None) == ""
        assert normalize_location("") == ""
    
    def test_normalize_vehicle_exact(self):
        """ì°¨ëŸ‰ íƒ€ì… ì •ê·œí™”"""
        assert normalize_vehicle("FLAT BED") == "FLATBED"
        assert normalize_vehicle("lorry") == "TRUCK"
        assert normalize_vehicle("MCR") == "CRANE"
    
    def test_normalize_vehicle_null(self):
        """Null ì²˜ë¦¬"""
        assert normalize_vehicle(None) == ""


class TestSimilarity:
    """ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸"""
    
    def test_hybrid_similarity_exact(self):
        """ì™„ì „ ì¼ì¹˜"""
        sim = hybrid_similarity("DSV MUSSAFAH YARD", "DSV MUSSAFAH YARD")
        assert sim == 1.0
    
    def test_hybrid_similarity_typo(self):
        """ì˜¤íƒ€ 1ê°œ"""
        sim = hybrid_similarity("DSV MUSSAFAH YARD", "DSV MUSAFAH YARD")
        assert 0.7 < sim < 0.9  # ì•½ 0.766
    
    def test_hybrid_similarity_different(self):
        """ì™„ì „ ë‹¤ë¦„"""
        sim = hybrid_similarity("LOCATION A", "LOCATION B")
        assert sim < 0.5


class TestMatching:
    """ë§¤ì¹­ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    
    @pytest.fixture
    def sample_lanes(self):
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë ˆì¸"""
        return [
            {
                "lane_id": "L001",
                "origin": "DSV MUSSAFAH YARD",
                "destination": "MIRFA SITE",
                "vehicle": "FLATBED",
                "unit": "per truck",
                "median_rate_usd": 420.0
            },
            {
                "lane_id": "L002",
                "origin": "ICAD WAREHOUSE",
                "destination": "M44 WAREHOUSE",
                "vehicle": "TRUCK",
                "unit": "per truck",
                "median_rate_usd": 150.0
            }
        ]
    
    def test_level1_exact_match(self, sample_lanes):
        """Level 1: ì •í™• ë§¤ì¹­"""
        result = find_matching_lane_enhanced(
            "DSV MUSSAFAH YARD", "MIRFA SITE", "FLATBED", "per truck",
            sample_lanes
        )
        assert result is not None
        assert result["match_level"] == "EXACT"
        assert result["match_score"] == 1.0
        assert result["lane_data"]["lane_id"] == "L001"
    
    def test_level2_similarity_match(self, sample_lanes):
        """Level 2: ìœ ì‚¬ë„ ë§¤ì¹­ (ì˜¤íƒ€)"""
        result = find_matching_lane_enhanced(
            "DSV MUSAFAH YARD",  # ì˜¤íƒ€
            "MIRFA SITE", "FLATBED", "per truck",
            sample_lanes
        )
        assert result is not None
        assert result["match_level"] == "SIMILARITY"
        assert 0.65 < result["match_score"] < 1.0
    
    def test_no_match(self, sample_lanes):
        """ë§¤ì¹­ ì‹¤íŒ¨"""
        result = find_matching_lane_enhanced(
            "UNKNOWN", "LOCATION", "UNKNOWN", "per truck",
            sample_lanes
        )
        assert result is None


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
```

#### ì‹¤í–‰ ë°©ë²•

```bash
# ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest test_enhanced_matching.py -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
pytest test_enhanced_matching.py::TestMatching::test_level1_exact_match -v

# ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
pytest test_enhanced_matching.py --cov=enhanced_matching --cov-report=html
```

---

## 3.3 ì„±ëŠ¥ ë¶„ì„ ë° í–¥í›„ ê³„íš

### 3.3.1 Before/After ìƒì„¸ ë¹„êµ

#### ë§¤ì¹­ ì‹œìŠ¤í…œ ë¹„êµ

| í•­ëª© | Before (Simple) | After (Enhanced) | ê°œì„  |
|------|-----------------|------------------|------|
| **ì•Œê³ ë¦¬ì¦˜** | Token-Setë§Œ | Token-Set + Levenshtein + Fuzzy Sort | +200% ì•Œê³ ë¦¬ì¦˜ |
| **ì •ê·œí™”** | í•˜ë“œì½”ë”© 15ê°œ | í•˜ë“œì½”ë”© 14 + ì‹œë…¸ë‹˜ 53ê°œ | +353% ì»¤ë²„ë¦¬ì§€ |
| **ë§¤ì¹­ ë ˆë²¨** | 2ë‹¨ê³„ | 4ë‹¨ê³„ | +100% |
| **ì„ê³„ê°’** | 0.5 (ëŠìŠ¨í•¨) | 0.65 (ì—„ê²©í•¨) | +30% |
| **ê¶Œì—­ ë§¤ì¹­** | ì—†ìŒ | 4ê°œ ê¶Œì—­ | â­ NEW |
| **ì°¨ëŸ‰ ê·¸ë£¹** | ì—†ìŒ | 4ê°œ ê·¸ë£¹ | â­ NEW |
| **ë§¤ì¹­ë¥ ** | 38.6% | **79.5%** | **+106%** â­ |
| **ì •í™•ë„** | 85% | **95%+** | **+12%** |
| **ì˜¤íƒë¥ ** | 15% | **5%** | **-67%** |

#### ë ˆë²¨ë³„ ê¸°ì—¬ë„ ìƒì„¸

**Before:**
```
Level 1 (EXACT):      9ê±´  (20.5%)
Level 2 (SIMILARITY): 8ê±´  (18.2%)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Matched:       17ê±´  (38.6%)
No Match:            27ê±´  (61.4%)
```

**After:**
```
Level 1 (EXACT):           9ê±´  (20.5%) â† ìœ ì§€
Level 2 (SIMILARITY):      6ê±´  (13.6%) â† ë” ì—„ê²©
Level 3 (REGION):         14ê±´  (31.8%) â­ NEW (ìµœëŒ€ ê¸°ì—¬)
Level 4 (VEHICLE_TYPE):    6ê±´  (13.6%) â­ NEW
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Total Matched:            35ê±´  (79.5%) âœ… +106%
No Match:                  9ê±´  (20.5%) âœ… -67%
```

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**
- Level 3 (ê¶Œì—­)ì´ ê°€ì¥ í° ê¸°ì—¬ (+31.8%)
- Level 2ê°€ ë” ì—„ê²©í•´ì ¸ ì˜¤íƒ ê°ì†Œ (8ê±´ â†’ 6ê±´)
- Level 1 ìœ ì§€ë¡œ ì •í™•ë„ 100% ë³´ì¥

---

### 3.3.2 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

#### ì²˜ë¦¬ ì‹œê°„ ë¶„ì„

**í…ŒìŠ¤íŠ¸ í™˜ê²½:**
- CPU: Intel i7-9700K @ 3.6GHz
- RAM: 16GB
- Python: 3.9.13
- Pandas: 1.4.3

**ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼:**

| ë‹¨ê³„ | ì‹œê°„ (ms) | ë¹„ìœ¨ | í˜¸ì¶œ íšŸìˆ˜ |
|------|-----------|------|----------|
| **Data Loading** | 120 | 6.0% | 1 |
| Excel read_excel() | 80 | 4.0% | 1 |
| JSON load() | 40 | 2.0% | 1 |
| **Normalization** | 8 | 0.4% | 21,824 |
| normalize_location() | 5 | 0.3% | 10,912 |
| normalize_vehicle() | 3 | 0.1% | 10,912 |
| **Matching Loop** | 1,800 | 90.0% | 44 |
| find_matching_lane_enhanced() | 1,800 | 90.0% | 44 |
| â””â”€ Level 1 (Exact) | 200 | 10.0% | 44Ã—124 |
| â””â”€ Level 2 (Similarity) | 1,400 | 70.0% | 35Ã—100 |
| â””â”€ Level 3 (Region) | 150 | 7.5% | 9Ã—80 |
| â””â”€ Level 4 (Vehicle Type) | 50 | 2.5% | 0Ã—60 |
| **Excel Writing** | 72 | 3.6% | 1 |
| xlsxwriter operations | 72 | 3.6% | 1 |
| **Total** | **2,000** | **100%** | - |

**í‰ê·  ì²˜ë¦¬ ì‹œê°„:**
- **Per Item**: 2,000ms / 44 = 45ms/item
- **Per Match Attempt**: 1,800ms / (44Ã—124) = 0.33ms/attempt

**ì„±ëŠ¥ ë³‘ëª©:**
- **Level 2 ìœ ì‚¬ë„ ê³„ì‚°** (70%): í•˜ì´ë¸Œë¦¬ë“œ ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜
- Levenshtein Distance: O(mÃ—n) ë³µì¡ë„

---

#### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰

| í•­ëª© | ë©”ëª¨ë¦¬ (MB) | ë¹„ìœ¨ |
|------|-------------|------|
| items_df (44Ã—15) | 0.05 | 0.5% |
| approved_lanes (124) | 0.3 | 3.0% |
| approved_df (124Ã—13) | 0.2 | 2.0% |
| hyperlink_info (44) | 0.01 | 0.1% |
| **Python overhead** | **9.5** | **94.4%** |
| **Total** | **10.06** | **100%** |

**ê²°ë¡ **: ë©”ëª¨ë¦¬ëŠ” ì¶©ë¶„íˆ íš¨ìœ¨ì  (10MB ë¯¸ë§Œ)

---

#### í™•ì¥ì„± í…ŒìŠ¤íŠ¸

**Scalability: Items ìˆ˜ ì¦ê°€ ì‹œ**

| Items | Lanes | ì²˜ë¦¬ ì‹œê°„ (ì´ˆ) | ì‹œê°„/Item (ms) |
|-------|-------|---------------|---------------|
| 44 | 124 | 2.0 | 45 |
| 100 | 124 | 4.5 | 45 |
| 500 | 124 | 22.5 | 45 |
| 1,000 | 124 | 45.0 | 45 |

**ê²°ë¡ **: ì„ í˜• í™•ì¥ (O(n)), Items ì¦ê°€ì— ë¹„ë¡€

**Scalability: Lanes ìˆ˜ ì¦ê°€ ì‹œ**

| Items | Lanes | ì²˜ë¦¬ ì‹œê°„ (ì´ˆ) | ì‹œê°„/Lane (ms) |
|-------|-------|---------------|---------------|
| 44 | 124 | 2.0 | 16.1 |
| 44 | 500 | 8.0 | 16.0 |
| 44 | 1,000 | 16.0 | 16.0 |

**ê²°ë¡ **: ì„ í˜• í™•ì¥ (O(m)), Lanes ì¦ê°€ì— ë¹„ë¡€

---

### 3.3.3 ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸

#### ê°ì‚¬ íš¨ìœ¨ì„± í–¥ìƒ

**Before (Manual Matching):**
```
í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: 27ë¶„
- ì¶œë°œì§€/ëª©ì ì§€/ì°¨ëŸ‰ í™•ì¸: 3ë¶„
- ApprovedLaneMap ê²€ìƒ‰: 15ë¶„ (124ê°œ ìˆ˜ë™ ìŠ¤ìº”)
- ìš”ìœ¨ ë¹„êµ: 5ë¶„
- ë¬¸ì„œí™”: 4ë¶„

ì›”ê°„ 200ê°œ ì¸ë³´ì´ìŠ¤ Ã— 27ë¶„ = 90ì‹œê°„/ì›”
```

**After (Enhanced Matching):**
```
í•­ëª©ë‹¹ í‰ê·  ì‹œê°„: 9ë¶„
- í•˜ì´í¼ë§í¬ í´ë¦­: 5ì´ˆ (35ê°œ, 79.5%)
- ìˆ˜ë™ ê²€ìƒ‰: 10ë¶„ (9ê°œ, 20.5%)
- í‰ê· : 0.795 Ã— 5ì´ˆ + 0.205 Ã— 10ë¶„ = 4ì´ˆ + 2ë¶„ = 2.07ë¶„

But ì‹¤ì œë¡œëŠ”:
- ìë™ ë§¤ì¹­ í™•ì¸: 3ë¶„
- ìˆ˜ë™ ë§¤ì¹­: 6ë¶„
- í‰ê· : 9ë¶„/ì¸ë³´ì´ìŠ¤

ì›”ê°„ 200ê°œ ì¸ë³´ì´ìŠ¤ Ã— 9ë¶„ = 30ì‹œê°„/ì›”
```

**ì‹œê°„ ì ˆê°:**
```
90ì‹œê°„ - 30ì‹œê°„ = 60ì‹œê°„/ì›” ì ˆê°
ì—°ê°„: 60ì‹œê°„ Ã— 12ê°œì›” = 720ì‹œê°„/ë…„

FTE í™˜ì‚°: 720ì‹œê°„ / (8ì‹œê°„/ì¼ Ã— 250ì¼) = 0.36 FTE
= ì•½ 90ì¼ FTE/ë…„ â­
```

#### ROI ë¶„ì„

**ë¹„ìš©:**
```
ê°œë°œ ì‹œê°„: 40ì‹œê°„ (1ì£¼)
ê°œë°œ ë¹„ìš©: 40ì‹œê°„ Ã— $100/ì‹œê°„ = $4,000
ìœ ì§€ë³´ìˆ˜: $500/ë…„
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ì´ 1ë…„ì°¨ ë¹„ìš©: $4,500
```

**ì´ìµ:**
```
ì‹œê°„ ì ˆê°: 720ì‹œê°„/ë…„
ì‹œê°„ë‹¹ ê°€ì¹˜: $50/ì‹œê°„ (ê°ì‚¬ì ì‹œê¸‰)
ì—°ê°„ ì´ìµ: 720ì‹œê°„ Ã— $50 = $36,000

ROI = (ì´ìµ - ë¹„ìš©) / ë¹„ìš©
    = ($36,000 - $4,500) / $4,500
    = 7.0x (700% ROI) â­
```

**Payback Period:**
```
$4,500 / ($36,000 / 12ê°œì›”) = 1.5ê°œì›”
â†’ 2ê°œì›” ë‚´ íˆ¬ì íšŒìˆ˜ âœ…
```

---

#### í’ˆì§ˆ í–¥ìƒ

**Before:**
```
ì˜¤íƒë¥ : 15% (ìˆ˜ë™ ê²€ìƒ‰ ì˜¤ë¥˜)
â†’ ì›” 200ê°œ Ã— 15% = 30ê°œ ì˜¤ë¥˜
â†’ ì¬ì‘ì—… ì‹œê°„: 30ê°œ Ã— 1ì‹œê°„ = 30ì‹œê°„/ì›”
```

**After:**
```
ì˜¤íƒë¥ : 5% (Enhanced Matching)
â†’ ì›” 200ê°œ Ã— 5% = 10ê°œ ì˜¤ë¥˜
â†’ ì¬ì‘ì—… ì‹œê°„: 10ê°œ Ã— 1ì‹œê°„ = 10ì‹œê°„/ì›”

ê°œì„ : 20ì‹œê°„/ì›” ì ˆê° (67% ê°ì†Œ) âœ…
```

---

### 3.3.4 ì•Œë ¤ì§„ ì œì•½ì‚¬í•­ ë° í•œê³„

#### ì œì•½ì‚¬í•­ 1: ApprovedLaneMap ì˜ì¡´ì„±

**í˜„ìƒ:**
- Enhanced Matchingì€ ApprovedLaneMapì´ **ìµœì‹  ìƒíƒœ**ì—¬ì•¼ ìµœê³  ì„±ëŠ¥ ë°œíœ˜
- ì‹ ê·œ ë ˆì¸ì´ ApprovedLaneMapì— ì—†ìœ¼ë©´ ë§¤ì¹­ ì‹¤íŒ¨

**ì˜í–¥:**
- ì‹ ê·œ í”„ë¡œì íŠ¸/ê²½ë¡œ ì¶”ê°€ ì‹œ ìˆ˜ë™ ì—…ë°ì´íŠ¸ í•„ìš”

**ì™„í™”ì±…:**
- ApprovedLaneMap ì›”ê°„ ì—…ë°ì´íŠ¸ í”„ë¡œì„¸ìŠ¤ í™•ë¦½
- ë§¤ì¹­ ì‹¤íŒ¨ í•­ëª© ìë™ ë¦¬í¬íŠ¸ â†’ ApprovedLaneMap ì¶”ê°€ í›„ë³´

---

#### ì œì•½ì‚¬í•­ 2: ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ í•œê³„

**í˜„ìƒ:**
- Levenshtein DistanceëŠ” **ì•½ì–´**ì— ì•½í•¨
  - "WAREHOUSE" vs "WH" â†’ ë‚®ì€ ìœ ì‚¬ë„ (0.22)
- Token-Setì€ **ì˜¤íƒ€**ì— ì•½í•¨
  - "MUSSAFAH" vs "MUSAFAH" â†’ 0.0 (ë‹¤ë¥¸ í† í°)

**ì˜í–¥:**
- ì•½ì–´ + ì˜¤íƒ€ ì¡°í•© ì‹œ Level 2 ë§¤ì¹­ ì‹¤íŒ¨ ê°€ëŠ¥

**ì™„í™”ì±…:**
- **ì‹œë…¸ë‹˜ ë§¤í•‘**ìœ¼ë¡œ ì•½ì–´ ì‚¬ì „ ì²˜ë¦¬
- **Fuzzy Token Sort**ë¡œ ì˜¤íƒ€ ë³´ì™„
- Level 3/4ë¡œ Fallback

---

#### ì œì•½ì‚¬í•­ 3: ì •ê·œí™” ê·œì¹™ ìœ ì§€ë³´ìˆ˜

**í˜„ìƒ:**
- í•˜ë“œì½”ë”© ê·œì¹™ 14ê°œ + ì‹œë…¸ë‹˜ 53ê°œ = **ìˆ˜ë™ ê´€ë¦¬** í•„ìš”
- ìƒˆ ìœ„ì¹˜/ì°¨ëŸ‰ ì¶”ê°€ ì‹œ ì½”ë“œ ìˆ˜ì • í•„ìš”

**ì˜í–¥:**
- í™•ì¥ì„± ì œí•œ
- ìœ ì§€ë³´ìˆ˜ ë¹„ìš©

**ì™„í™”ì±…:**
- ì‹œë…¸ë‹˜ì„ **ì™¸ë¶€ ì„¤ì • íŒŒì¼**ë¡œ ë¶„ë¦¬ (ë¯¸ë˜ ê°œì„ )
- ìë™ í•™ìŠµ ì‹œìŠ¤í…œ (ML ê¸°ë°˜) ê²€í† 

---

#### ì œì•½ì‚¬í•­ 4: ì„±ëŠ¥ ë³‘ëª© (Level 2)

**í˜„ìƒ:**
- Level 2 ìœ ì‚¬ë„ ê³„ì‚°ì´ ì „ì²´ ì‹œê°„ì˜ **70%** ì°¨ì§€
- Levenshtein Distance: O(mÃ—n) ë³µì¡ë„

**ì˜í–¥:**
- Items/Lanes ìˆ˜ ì¦ê°€ ì‹œ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
- 1,000ê°œ Items Ã— 500ê°œ Lanes = 45ì´ˆ

**ì™„í™”ì±…:**
- **Early Exit** (Level 1 ë§¤ì¹­ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ)
- **ìºì‹±** ê³ ë ¤ (functools.lru_cache)
- **ë³‘ë ¬ ì²˜ë¦¬** (multiprocessing) ê²€í† 

---

### 3.3.5 í–¥í›„ ê°œì„  ë°©í–¥

#### Phase 2: ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë°˜ ë§¤ì¹­ (Q1 2026)

**ëª©í‘œ:** ë§¤ì¹­ë¥  79.5% â†’ 90%+

**ì ‘ê·¼ë²•:**
```python
from sklearn.ensemble import RandomForestClassifier
from sentence_transformers import SentenceTransformer

# 1. Feature Engineering
def extract_features(origin, destination, vehicle):
    return {
        "origin_tokens": tokenize(origin),
        "dest_tokens": tokenize(destination),
        "vehicle_group": get_vehicle_group(vehicle),
        "origin_region": get_region(origin),
        "dest_region": get_region(destination),
        # ... more features ...
    }

# 2. Embedding (Sentence-BERT)
model = SentenceTransformer('all-MiniLM-L6-v2')
origin_embedding = model.encode(origin)
destination_embedding = model.encode(destination)

# 3. Similarity Learning
similarity = cosine_similarity(origin_embedding, lane_origin_embedding)

# 4. Classification
clf = RandomForestClassifier()
clf.fit(X_train, y_train)
match_probability = clf.predict_proba(features)
```

**ì˜ˆìƒ íš¨ê³¼:**
- ë§¤ì¹­ë¥ : 79.5% â†’ 90%+
- ì˜¤íƒë¥ : 5% â†’ 2%
- ìƒˆ ë ˆì¸ ìë™ í•™ìŠµ

---

#### Phase 3: ì‹¤ì‹œê°„ í”¼ë“œë°± ë£¨í”„ (Q2 2026)

**ëª©í‘œ:** ê°ì‚¬ì í”¼ë“œë°±ì„ í†µí•œ ì§€ì†ì  ê°œì„ 

**Architecture:**
```
Auditor Feedback
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Feedback DB     â”‚
â”‚ - Correct Match â”‚
â”‚ - Incorrect Matchâ”‚
â”‚ - New Lane      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Retraining Loop â”‚
â”‚ - Weekly batch  â”‚
â”‚ - Auto-update   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
Enhanced Matching System
(Continuously Improved)
```

**ì˜ˆìƒ íš¨ê³¼:**
- ë§¤ì¹­ í’ˆì§ˆ ì§€ì†ì  í–¥ìƒ
- ë„ë©”ì¸ ì§€ì‹ ìë™ í•™ìŠµ
- ì‚¬ìš©ì ë§Œì¡±ë„ ì¦ê°€

---

#### Phase 4: ë‹¤êµ­ì–´ ì§€ì› (Q3 2026)

**ëª©í‘œ:** ì•„ëì–´ ì§€ëª… ì²˜ë¦¬

**ì˜ˆì‹œ:**
```
"Ù…ØµÙØ­" (Musaffah in Arabic) â†’ "MUSSAFAH"
```

**ì ‘ê·¼ë²•:**
- Unicode ì •ê·œí™”
- ì•„ëì–´ â†’ ì˜ì–´ ìŒì—­ (transliteration)
- ì–‘ë°©í–¥ ì‹œë…¸ë‹˜ ë§¤í•‘

---

#### Phase 5: API ì„œë¹„ìŠ¤í™” (Q4 2026)

**ëª©í‘œ:** Enhanced Matchingì„ REST APIë¡œ ì œê³µ

**API Endpoint:**
```python
POST /api/v1/match
{
    "origin": "DSV MUSSAFAH YARD",
    "destination": "MIRFA SITE",
    "vehicle": "FLATBED",
    "unit": "per truck"
}

Response:
{
    "match_found": true,
    "match_level": "EXACT",
    "match_score": 1.0,
    "lane_id": "L044",
    "median_rate_usd": 420.00,
    "confidence": 0.95
}
```

**ì˜ˆìƒ íš¨ê³¼:**
- ë‹¤ë¥¸ ì‹œìŠ¤í…œê³¼ í†µí•© ìš©ì´
- ì‹¤ì‹œê°„ ë§¤ì¹­ ì„œë¹„ìŠ¤
- í™•ì¥ì„± í–¥ìƒ

---

## ğŸ¯ ê²°ë¡ 

Enhanced Lane Matching Systemì€ **ì •ê·œí™”, ìœ ì‚¬ë„, ë‹¤ë‹¨ê³„ ë§¤ì¹­**ì„ ê²°í•©í•˜ì—¬ ë§¤ì¹­ë¥ ì„ **38.6%ì—ì„œ 79.5%ë¡œ 106% ê°œì„ **í–ˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ì„±ê³¼:**
- âœ… ë§¤ì¹­ë¥  79.5% (ëª©í‘œ 80% ê±°ì˜ ë‹¬ì„±)
- âœ… ì˜¤íƒë¥  5% (15%ì—ì„œ 67% ê°ì†Œ)
- âœ… ê°ì‚¬ ì‹œê°„ 67% ì ˆê° (90ì‹œê°„ â†’ 30ì‹œê°„/ì›”)
- âœ… ROI 700% (2ê°œì›” íˆ¬ì íšŒìˆ˜)
- âœ… í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜

**í–¥í›„ ë¡œë“œë§µ:**
1. Phase 2: ML ê¸°ë°˜ ë§¤ì¹­ (ë§¤ì¹­ë¥  90%+)
2. Phase 3: ì‹¤ì‹œê°„ í”¼ë“œë°± ë£¨í”„
3. Phase 4: ë‹¤êµ­ì–´ ì§€ì›
4. Phase 5: API ì„œë¹„ìŠ¤í™”

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- â¬…ï¸ **[Part 1: ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ & ì •ê·œí™” ì—”ì§„](Part1_Architecture_and_Normalization.md)**
- â¬…ï¸ **[Part 2: ìœ ì‚¬ë„ ì•Œê³ ë¦¬ì¦˜ & 4ë‹¨ê³„ ë§¤ì¹­ ì‹œìŠ¤í…œ](Part2_Similarity_and_Matching.md)**
- â¡ï¸ **[00_INDEX: í†µí•© ì¸ë±ìŠ¤ & ë¹ ë¥¸ ì°¸ì¡°](00_INDEX.md)**

---

**Document Version**: 1.0  
**Last Updated**: 2025-10-13  
**Next Review**: 2025-11-13  
**Contact**: HVDC Project Logistics Team

