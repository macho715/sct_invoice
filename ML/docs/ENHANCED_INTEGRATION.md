# ğŸ”— Enhanced ML System - Integration Guide

## ê°œìš”

ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê°œì„ ëœ Enhanced ML System ê°„ì˜ í†µí•© ë°©ë²• ë° ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ¯ í†µí•© ì „ëµ

### 1. ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ (ê¶Œì¥)

ê¸°ì¡´ ì‹œìŠ¤í…œì„ ìœ ì§€í•˜ë©´ì„œ ê°œì„ ëœ ì‹œìŠ¤í…œì„ ì ì§„ì ìœ¼ë¡œ ë„ì…í•˜ëŠ” ì „ëµì…ë‹ˆë‹¤.

```mermaid
graph LR
    A[ê¸°ì¡´ ì‹œìŠ¤í…œ] --> B[ë³‘ë ¬ ì‹¤í–‰]
    B --> C[ì„±ëŠ¥ ë¹„êµ]
    C --> D[ì ì§„ì  ì „í™˜]
    D --> E[Enhanced System]
```

### 2. A/B í…ŒìŠ¤íŠ¸ ê¸°ë°˜ ì „í™˜

```python
# ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ê°œì„  ì‹œìŠ¤í…œ ë™ì‹œ ì‹¤í–‰
from unified_ml_pipeline import UnifiedMLPipeline
from enhanced_unified_ml_pipeline import EnhancedUnifiedMLPipeline

# ê¸°ì¡´ ì‹œìŠ¤í…œ
old_pipeline = UnifiedMLPipeline()

# ê°œì„ ëœ ì‹œìŠ¤í…œ
new_pipeline = EnhancedUnifiedMLPipeline()

# A/B í…ŒìŠ¤íŠ¸ë¡œ ì„±ëŠ¥ ë¹„êµ
ab_results = new_pipeline.run_ab_test(test_data, approved_lanes)
```

---

## ğŸ“‹ ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

### Phase 1: í™˜ê²½ ì¤€ë¹„ (1ì¼)

#### 1.1 ì˜ì¡´ì„± ì„¤ì¹˜

```bash
# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install numpy pandas scikit-learn scipy

# ê¸°ì¡´ ì˜ì¡´ì„± í™•ì¸
pip list | grep -E "(numpy|pandas|scikit-learn)"
```

#### 1.2 ì„¤ì • íŒŒì¼ ìƒì„±

`config.json` ìƒì„±:

```json
{
  "paths": {
    "approved_lanes": "logi_costguard_ml_v2/ref/inland_trucking_reference_rates_clean.json",
    "lane_map": "logi_costguard_ml_v2/ref/ApprovedLaneMap.csv",
    "schema": "logi_costguard_ml_v2/config/schema.json",
    "models_dir": "output/models",
    "output_dir": "output",
    "logs_dir": "logs"
  },
  "ml": {
    "default_weights": {
      "token_set": 0.4,
      "levenshtein": 0.3,
      "fuzzy_sort": 0.3
    },
    "similarity_threshold": 0.65,
    "use_ml_weights": true,
    "test_size": 0.2
  },
  "costguard": {
    "tolerance": 3.0,
    "auto_fail": 15.0,
    "bands": {
      "pass": 2.0,
      "warn": 5.0,
      "high": 10.0
    }
  },
  "processing": {
    "chunk_size": 1000,
    "n_workers": 4
  }
}
```

#### 1.3 ë””ë ‰í† ë¦¬ êµ¬ì¡° ì„¤ì •

```bash
# í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p output/models
mkdir -p output
mkdir -p logs

# ê¶Œí•œ ì„¤ì • (Linux/Mac)
chmod 755 output models logs
```

### Phase 2: í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì¶• (2-3ì¼)

#### 2.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```python
# ê°œì„ ëœ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
python test_enhanced_system.py

# ê¸°ì¡´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
python -m pytest test_integration_e2e.py -v
```

**ì˜ˆìƒ ê²°ê³¼:**
```
ì´ í…ŒìŠ¤íŠ¸: 4
OK í†µê³¼: 4
FAIL ì‹¤íŒ¨: 0
SUCCESS ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!
```

#### 2.2 í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```python
# E2E í†µí•© í…ŒìŠ¤íŠ¸
python -m pytest test_integration_e2e.py::TestE2ETrainingPipeline -v
python -m pytest test_integration_e2e.py::TestE2EPredictionPipeline -v
```

**ì˜ˆìƒ ê²°ê³¼:**
```
8 passed, 1 warning in 5.20s
```

#### 2.3 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
# ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
from vectorized_processing import VectorizedSimilarity
import time

# ë²¡í„°í™” ì—°ì‚° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
vectorized_sim = VectorizedSimilarity()
sources = ["Origin " + str(i) for i in range(100)]
targets = ["Target " + str(i) for i in range(50)]
weights = {'token_set': 0.45, 'levenshtein': 0.25, 'fuzzy_sort': 0.30}

start = time.time()
similarity_matrix = vectorized_sim.batch_similarity(sources, targets, weights)
elapsed = time.time() - start

print(f"Rate: {100*50/elapsed:.0f} comparisons/sec")
# ì˜ˆìƒ ê²°ê³¼: Rate: 203987 comparisons/sec
```

### Phase 3: ì ì§„ì  ì „í™˜ (1ì£¼)

#### 3.1 ì½ê¸° ì „ìš© ì‘ì—…ë¶€í„° ì‹œì‘

```python
# 1ë‹¨ê³„: ì˜ˆì¸¡ ì‘ì—…ë§Œ ê°œì„  ì‹œìŠ¤í…œ ì‚¬ìš©
from enhanced_unified_ml_pipeline import EnhancedUnifiedMLPipeline

pipeline = EnhancedUnifiedMLPipeline("config.json")

# ê¸°ì¡´ ë°ì´í„°ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
results = pipeline.predict_all(invoice_data, approved_lanes)
print(f"Processed: {len(results)} items")
```

#### 3.2 A/B í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```python
# 2ë‹¨ê³„: A/B í…ŒìŠ¤íŠ¸ë¡œ ì„±ëŠ¥ ê²€ì¦
ab_results = pipeline.run_ab_test(test_data, approved_lanes)

# ê²°ê³¼ ë¶„ì„
for metric in ['accuracy', 'precision', 'recall', 'f1']:
    improvement = ab_results['improvement'][metric]
    print(f"{metric.capitalize()}: {improvement:+.2%}")
```

#### 3.3 í•™ìŠµ ì‘ì—… ì „í™˜

```python
# 3ë‹¨ê³„: í•™ìŠµ ì‘ì—…ë„ ê°œì„  ì‹œìŠ¤í…œ ì‚¬ìš©
training_results = pipeline.train_all(
    invoice_data=invoice_data,
    matching_data=matching_data,
    retrain=False
)

print(f"CostGuard MAPE: {training_results['costguard']['mape']:.3f}")
print(f"Weight Optimizer Accuracy: {training_results['weight_optimizer']['accuracy']:.3f}")
```

### Phase 4: í”„ë¡œë•ì…˜ ë°°í¬ (1-2ì¼)

#### 4.1 ëª¨ë‹ˆí„°ë§ ì„¤ì •

```python
# ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì„¤ì •
from error_handling import get_error_tracker

# ì—ëŸ¬ í†µê³„ í™•ì¸
tracker = get_error_tracker()
stats = tracker.get_statistics()
print(f"Total Errors: {stats['total_errors']}")
print(f"Most Common Error: {stats['most_common_error']}")
```

#### 4.2 ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

```python
# ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
import time
from pathlib import Path

def monitor_performance():
    start_time = time.time()

    # ì‘ì—… ì‹¤í–‰
    results = pipeline.predict_all(invoice_data, approved_lanes)

    elapsed = time.time() - start_time
    rate = len(results) / elapsed

    # ë¡œê·¸ ê¸°ë¡
    log_data = {
        'timestamp': time.time(),
        'items_processed': len(results),
        'elapsed_time': elapsed,
        'processing_rate': rate,
        'error_count': stats['total_errors']
    }

    return log_data
```

---

## ğŸ”„ API í˜¸í™˜ì„± ë§¤íŠ¸ë¦­ìŠ¤

### ê¸°ì¡´ API â†’ ê°œì„ ëœ API ë§¤í•‘

| ê¸°ì¡´ ë©”ì„œë“œ | ê°œì„ ëœ ë©”ì„œë“œ | í˜¸í™˜ì„± | ë³€ê²½ì‚¬í•­ |
|-------------|---------------|--------|----------|
| `train_all()` | `train_all()` | âœ… 100% | ë‚´ë¶€ êµ¬í˜„ë§Œ ê°œì„  |
| `predict_all()` | `predict_all()` | âœ… 100% | ë²¡í„°í™” ì—°ì‚° ì ìš© |
| `run_ab_test()` | `run_ab_test()` | âœ… 100% | ì—ëŸ¬ í•¸ë“¤ë§ ê°•í™” |
| `get_statistics()` | `get_statistics()` | âœ… 100% | ì—ëŸ¬ í†µê³„ ì¶”ê°€ |

### ì„¤ì • íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜

#### ê¸°ì¡´ í•˜ë“œì½”ë”© â†’ ì„¤ì • íŒŒì¼

```python
# âŒ ê¸°ì¡´: í•˜ë“œì½”ë”©ëœ ì„¤ì •
DEFAULT_WEIGHTS = {"token_set": 0.4, "levenshtein": 0.3, "fuzzy_sort": 0.3}
lane_map = "logi_costguard_ml_v2/ref/ApprovedLaneMap.csv"

# âœ… ê°œì„ : ì„¤ì • íŒŒì¼ ê¸°ë°˜
config = get_config("config.json")
weights = config.get('ml.default_weights')
lane_map_path = config.get_path('lane_map')
```

#### í™˜ê²½ ë³€ìˆ˜ ì§€ì›

```bash
# í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
export ML_MODELS_DIR="/path/to/models"
export ML_USE_ML_WEIGHTS="true"
export ML_LOG_LEVEL="INFO"
```

---

## ğŸ› ï¸ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ

### ì¼ë°˜ì ì¸ ë¬¸ì œ

#### 1. ì„¤ì • íŒŒì¼ ì˜¤ë¥˜

**ë¬¸ì œ:** `ConfigurationError: Configuration validation failed`

**í•´ê²°ë°©ë²•:**
```python
# ì„¤ì • ê²€ì¦
config = get_config("config.json")
if not config.validate():
    print("Configuration validation failed")
    # config.json íŒŒì¼ í™•ì¸
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡±

**ë¬¸ì œ:** ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ ë©”ëª¨ë¦¬ ë¶€ì¡±

**í•´ê²°ë°©ë²•:**
```python
# ì²­í¬ í¬ê¸° ì¡°ì •
processor = BatchProcessor(
    chunk_size=500,  # 1000 â†’ 500ìœ¼ë¡œ ê°ì†Œ
    n_workers=2      # 4 â†’ 2ë¡œ ê°ì†Œ
)
```

#### 3. ì„±ëŠ¥ ì €í•˜

**ë¬¸ì œ:** ë²¡í„°í™” ì—°ì‚°ì´ ì˜ˆìƒë³´ë‹¤ ëŠë¦¼

**í•´ê²°ë°©ë²•:**
```python
# ìºì‹œ í¬ê¸° ì¡°ì •
vectorized_sim = VectorizedSimilarity(cache_size=2000)  # ê¸°ë³¸ê°’ 1000 â†’ 2000

# ì›Œì»¤ ìˆ˜ ì¡°ì •
processor = BatchProcessor(
    chunk_size=1000,
    n_workers=8  # CPU ì½”ì–´ ìˆ˜ë§Œí¼ ì¦ê°€
)
```

### ë¡œê·¸ ë¶„ì„

#### ì—ëŸ¬ ë¡œê·¸ í™•ì¸

```python
from error_handling import get_error_tracker

# ì—ëŸ¬ í†µê³„ í™•ì¸
tracker = get_error_tracker()
stats = tracker.get_statistics()

print(f"Total Errors: {stats['total_errors']}")
print(f"Error Counts: {stats['error_counts']}")
print(f"Most Common Error: {stats['most_common_error']}")

# ìµœê·¼ ì—ëŸ¬ í™•ì¸
recent_errors = tracker.get_recent_errors(n=5)
for error in recent_errors:
    print(f"  [{error['timestamp']}] {error['type']}: {error['message']}")
```

#### ì„±ëŠ¥ ë¡œê·¸ ë¶„ì„

```python
import json
from pathlib import Path

# ë¡œê·¸ íŒŒì¼ ë¶„ì„
log_file = Path("logs/unified_ml_pipeline.log")
if log_file.exists():
    with open(log_file, 'r') as f:
        logs = [json.loads(line) for line in f if line.startswith('{')]

    # ì„±ëŠ¥ ê´€ë ¨ ë¡œê·¸ í•„í„°ë§
    perf_logs = [log for log in logs if 'completed in' in log.get('message', '')]
    for log in perf_logs[-5:]:
        print(f"  {log['message']}")
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ ë° ê²€ì¦

### ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸

```python
def benchmark_comparison():
    """ê¸°ì¡´ vs ê°œì„  ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ"""

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
    test_data = pd.read_excel("test_invoices.xlsx")

    # ê¸°ì¡´ ì‹œìŠ¤í…œ
    from unified_ml_pipeline import UnifiedMLPipeline
    old_pipeline = UnifiedMLPipeline()

    start = time.time()
    old_results = old_pipeline.predict_all(test_data, approved_lanes)
    old_time = time.time() - start

    # ê°œì„  ì‹œìŠ¤í…œ
    from enhanced_unified_ml_pipeline import EnhancedUnifiedMLPipeline
    new_pipeline = EnhancedUnifiedMLPipeline()

    start = time.time()
    new_results = new_pipeline.predict_all(test_data, approved_lanes)
    new_time = time.time() - start

    # ê²°ê³¼ ë¹„êµ
    improvement = (old_time - new_time) / old_time * 100

    print(f"ê¸°ì¡´ ì‹œìŠ¤í…œ: {old_time:.3f}ì´ˆ")
    print(f"ê°œì„  ì‹œìŠ¤í…œ: {new_time:.3f}ì´ˆ")
    print(f"ì„±ëŠ¥ í–¥ìƒ: {improvement:.1f}%")

    return {
        'old_time': old_time,
        'new_time': new_time,
        'improvement': improvement,
        'old_results_count': len(old_results),
        'new_results_count': len(new_results)
    }
```

### ì˜ˆìƒ ì„±ëŠ¥ ê°œì„ 

| í•­ëª© | ê¸°ì¡´ | ê°œì„  | ê°œì„ ìœ¨ |
|------|------|------|--------|
| **ë°°ì¹˜ ì²˜ë¦¬** | 10ì´ˆ/100 items | 0.2ì´ˆ/100 items | **50ë°°** |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©** | 500MB | 150MB | **70% ê°ì†Œ** |
| **ìœ ì‚¬ë„ ê³„ì‚°** | 1,000/sec | 203,987/sec | **204ë°°** |
| **ì—ëŸ¬ ë³µêµ¬** | ìˆ˜ë™ | ìë™ | **100% ìë™í™”** |

---

## ğŸ”’ ë¡¤ë°± ì „ëµ

### ì¦‰ì‹œ ë¡¤ë°±

ë¬¸ì œ ë°œìƒ ì‹œ ì¦‰ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ë³µêµ¬:

```python
# ê°œì„  ì‹œìŠ¤í…œì—ì„œ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ë¡¤ë°±
from unified_ml_pipeline import UnifiedMLPipeline

# ì¦‰ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œ ì‚¬ìš©
pipeline = UnifiedMLPipeline()
results = pipeline.predict_all(invoice_data, approved_lanes)
```

### ì ì§„ì  ë¡¤ë°±

```python
# ì„¤ì • íŒŒì¼ë¡œ ë¡¤ë°±
config = {
    "ml": {
        "use_ml_weights": False,  # ML ê°€ì¤‘ì¹˜ ë¹„í™œì„±í™”
        "fallback_to_default": True
    }
}

pipeline = EnhancedUnifiedMLPipeline()
# ê¸°ë³¸ ê°€ì¤‘ì¹˜ë¡œ ë™ì‘
```

### ë°ì´í„° ë¡¤ë°±

```python
# ì´ì „ ëª¨ë¸ íŒŒì¼ë¡œ ë³µêµ¬
import shutil
from pathlib import Path

# ë°±ì—…ëœ ëª¨ë¸ íŒŒì¼ ë³µì›
backup_dir = Path("backup/models")
current_dir = Path("output/models")

if backup_dir.exists():
    shutil.rmtree(current_dir)
    shutil.copytree(backup_dir, current_dir)
    print("Model files restored from backup")
```

---

## âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì‚¬ì „ ì¤€ë¹„

- [ ] ì˜ì¡´ì„± íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] ì„¤ì • íŒŒì¼ (`config.json`) ìƒì„± ë° ê²€ì¦
- [ ] í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„± (`output/`, `logs/`)
- [ ] ë°±ì—… íŒŒì¼ ìƒì„± (ê¸°ì¡´ ëª¨ë¸, ì„¤ì •)

### í…ŒìŠ¤íŠ¸ ë‹¨ê³„

- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼ (4/4)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ í†µê³¼ (8/8)
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
- [ ] A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸

### ë°°í¬ ë‹¨ê³„

- [ ] ì½ê¸° ì „ìš© ì‘ì—… ì „í™˜ ì™„ë£Œ
- [ ] í•™ìŠµ ì‘ì—… ì „í™˜ ì™„ë£Œ
- [ ] ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì •
- [ ] ì—ëŸ¬ ì•Œë¦¼ ì‹œìŠ¤í…œ ì„¤ì •

### ê²€ì¦ ë‹¨ê³„

- [ ] ì„±ëŠ¥ ê°œì„  í™•ì¸ (50ë°° ì´ìƒ)
- [ ] ì—ëŸ¬ìœ¨ ê°ì†Œ í™•ì¸
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ í™•ì¸
- [ ] ë¡œê·¸ í’ˆì§ˆ í–¥ìƒ í™•ì¸

---

## ğŸ“ ì§€ì› ë° ë¬¸ì˜

### ë¬¸ì œ ë°œìƒ ì‹œ

1. **ë¡œê·¸ í™•ì¸**: `logs/` ë””ë ‰í† ë¦¬ì˜ ë¡œê·¸ íŒŒì¼ ê²€í† 
2. **ì—ëŸ¬ í†µê³„**: `get_error_tracker().get_statistics()` ì‹¤í–‰
3. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
4. **ë¡¤ë°± ì‹¤í–‰**: ë¬¸ì œ ì‹œ ì¦‰ì‹œ ê¸°ì¡´ ì‹œìŠ¤í…œìœ¼ë¡œ ë³µêµ¬

### ì¶”ê°€ ì§€ì›

- **GitHub Issues**: ê¸°ìˆ ì  ë¬¸ì œ ë³´ê³ 
- **ë¬¸ì„œ ì°¸ì¡°**: [Enhanced Integration Guide](../ENHANCED_INTEGRATION_GUIDE.md)
- **ì„±ëŠ¥ ê°€ì´ë“œ**: [System Comparison](./SYSTEM_COMPARISON.md)

---

**ì„±ê³µì ì¸ ë§ˆì´ê·¸ë ˆì´ì…˜ìœ¼ë¡œ Enhanced ML Systemì˜ ì„±ëŠ¥ê³¼ ì•ˆì •ì„±ì„ ê²½í—˜í•˜ì„¸ìš”!** ğŸš€
